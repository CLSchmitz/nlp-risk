# nlp-risk

## Instructions for reading the project directory

The directory contains four folders, /data, which contains all the raw, processed, and labeled data for the project; /models, which contains the project's trained model, /results, which contains the results visualizations, and /src, which contains the python scripts for data processing, analysis, and presentation. It also contains requirements.txt, a list of packages that are necessary to run the code locally. The model is too large to upload, so must be trained using a script.

The scripts in src are numbered in order of execution. As detailed below, it is possible to replicate the entire second half of the project, starting from the raw data gathered through RPA, by running these scripts in order, <b>with exception of the data labeling step between scripts 00 and 01, which was done manually</b>. 

The inputs, process, and output of each script are outlined below.

![repo structure](https://github.com/CLSchmitz/nlp-risk/blob/master/repo_structure.PNG)

## Instructions for replicating the project locally

A list of required packages that are used in the project is provided. In order to install them, it is recommended to use [Anaconda](https://www.anaconda.com/products/individual). Clone or download the repository onto your PC. Using anaconda prompt, create and activate a new conda environment using `conda env create -n nlp_env` and `conda activate nlp_env`. Install the required packages into this environment, by navigating to the project folder and running `pip install -r requirements.txt`. You should now be able to execute all python scripts in this folder.

### To replicate the full process:

To validate each script, the script's output can be deleted from its place in the repository, and the script can be run. For example, to validate 00_data_consolidation_and_cleaning.py, one can delete data_clean.csv from data/processed, navigate to src, and run `python 00_data_consolidation_and_cleaning.py` in anaconda prompt. If one wishes to rerun every script, the entire contents of the folders /models, /data/processed, and /results can be deleted (but not the folders themselves!), and all scripts can be run in order. <b> data/raw, data/test, and data/processed_labeled cannot be deleted</b>, as their contents are not generated by a script, but the product of RPA and of manual labeling, respectively. 

### To replicate results generation:

To only replicate the process by which the samples used in the final presentation were created, only the final script must be run. For this all other files, including the model, must be in place.

